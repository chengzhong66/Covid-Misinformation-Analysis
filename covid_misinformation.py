# -*- coding: utf-8 -*-
"""Covid misinformation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k0-INT_QtbKdybNv7ngJxGKFIR03A65K

### Predict Covid Tweets Misinformation
Cheng Zhong <br>
cz2632@columbia.edu <br>
github link to the project: https://github.com/chengzhong666/Covid-Misinformation-Analysis

### Citation of paper providing original dataset
Shahi, Gautam Kishore, Anne Dirkson, and Tim A. Majchrzak. "An exploratory study of covid-19 misinformation on twitter." Online Social Networks and Media 22 (2021): 100104.
"""

# Commented out IPython magic to ensure Python compatibility.
# Colab Setup: 
# note that tabular preprocessors require scikit-learn>=0.24.0
# Newest Tensorflow 2 has some bugs for onnx conversion
!pip install scikit-learn --upgrade 
import os
os.environ['TF_KERAS'] = '1'
# % tensorflow_version 1

#Source: Fighting an Infodemic: COVID-19 Fake News Dataset, https://github.com/diptamath/covid_fake_news,https://arxiv.org/abs/2011.03327 

import pandas as pd
trainingdata=pd.read_csv("https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/Constraint_Train.csv", usecols = ['tweet','label'])
testdata=pd.read_csv("https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data/english_test_with_labels.csv", usecols = ['tweet','label'])

trainingdata.head()

"""### Examples of tweets from the dataset that demonstrate real information or misinformation"""

real_tweets = list(trainingdata[trainingdata['label'] == 'real']['tweet'])
fake_tweets = list(trainingdata[trainingdata['label'] == 'fake']['tweet'])

real_tweets[0]

real_tweets[1]

real_tweets[2]

fake_tweets[0]

fake_tweets[1]

fake_tweets[2]

"""### Discuss the dataset in general terms and describe why building a predictive model using this data might be practically useful.  Who could benefit from a model like this? Explain."""

trainingdata.describe()

testdata.describe()

"""This dataset contains text data on covid-19 information tweets. The labels for the tweets are two categories, real and false. Building a predictive model using that is practically useful for identifying the truthfulness of information. It could improve the efficiency for the public to adopt correct knowledge for covid and prevent the spread of rumors.

The text data reflect different patterns for true and false tweets. For instance, veracious tweets generally show a neutral tone, use informative language, and avoid hateful speech. On the other hand, false news tweets show their inflammatory nature, deny scientific approaches to fight over the pandemic, and incite ignorance and hatred.

By applying deep learning algorithms to this dataset, these patterns of real and false tweets could be analyzed and identified in a relatively automated way. The models generated could be used for future inputs, and the decision makers could predict future trends and regulations and optimize resources.

### Run at least four prediction models to try to predict real or fake tweets well.
- Use Embedding layers and at least one LSTM layer for at least one of these models
- Experiment with Bidirectional LSTMs, stacked LSTMS, and dropout regularization with at least two models.
- Use Embedding layers and at least one 1D Convolution layer for at least one of these models
- Discuss which models performed better and point out relevant hyper-parameter values for successful models.
"""

# Define preprocessor

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

# Build vocabulary from training text data
tokenizer = Tokenizer(num_words=10000)
tokenizer.fit_on_texts(trainingdata.tweet)

# preprocessor tokenizes words and makes sure all documents have the same length
def preprocessor(data, maxlen, max_words):

    sequences = tokenizer.texts_to_sequences(data)

    word_index = tokenizer.word_index
    X = pad_sequences(sequences, maxlen=maxlen)

    return X

# Prepare train and test data

# tokenize and pad X data
X_train = preprocessor(trainingdata.tweet, maxlen=40, max_words=10000)
X_test = preprocessor(testdata.tweet, maxlen=40, max_words=10000)

# one encode Y data
y_train = pd.get_dummies(trainingdata.label)
y_test = pd.get_dummies(testdata.label)

print(X_train.shape)
print(X_test.shape)

trainingdata.label.value_counts()

testdata.label.value_counts()

# load model_eval_metrics() function to calculate metrics

import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
import pandas as pd
from math import sqrt

def model_eval_metrics(y_true, y_pred,classification="TRUE"):
     if classification=="TRUE":
        accuracy_eval = accuracy_score(y_true, y_pred)
        f1_score_eval = f1_score(y_true, y_pred,average="macro",zero_division=0)
        precision_eval = precision_score(y_true, y_pred,average="macro",zero_division=0)
        recall_eval = recall_score(y_true, y_pred,average="macro",zero_division=0)
        mse_eval = 0
        rmse_eval = 0
        mae_eval = 0
        r2_eval = 0
        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}
        finalmetricdata = pd.DataFrame.from_dict(metricdata)
     else:
        accuracy_eval = 0
        f1_score_eval = 0
        precision_eval = 0
        recall_eval = 0
        mse_eval = mean_squared_error(y_true, y_pred)
        rmse_eval = sqrt(mean_squared_error(y_true, y_pred))
        mae_eval = mean_absolute_error(y_true, y_pred)
        r2_eval = r2_score(y_true, y_pred)
        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}
        finalmetricdata = pd.DataFrame.from_dict(metricdata)
     return finalmetricdata

# Callbacks

from tensorflow.python.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping 
mc = ModelCheckpoint('best_model_embeddings.h5', monitor='acc',mode='max', verbose=1, save_best_only=True) 
red_lr= ReduceLROnPlateau(monitor='acc',patience=2,verbose=1,factor=0.5, min_lr=0.001)
es = EarlyStopping(monitor='acc', mode='max', verbose=1, patience=3)

"""### Train Placeholder Model
1 embedding layer + 1 dense layer
"""

from tensorflow.keras.layers import Dense, Embedding, Flatten
from tensorflow.keras.models import Sequential

# replace this model with the architectures from the task description
model = Sequential()
model.add(Embedding(10000, 16, input_length=40))
model.add(Flatten())
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])

history = model.fit(X_train, y_train,
                    epochs=10,
                    batch_size=32,
                    validation_split=0.2)

# format y_pred as labels 
y_pred = model.predict(X_test).argmax(axis=1)
predicted_labels = [y_test.columns[i] for i in y_pred]
predicted_labels[0:5]

"""### Model 1
1 embedding layer + 2 LSTM layers
(no dropout regularization)
"""

maxlen = 40
max_words = 10000 
embedding_dim = 100

from tensorflow.keras.layers import Dense, Embedding,Flatten, LSTM
from tensorflow.keras.models import Sequential
model1 = Sequential()
model1.add(Embedding(max_words, embedding_dim, input_length=maxlen))
model1.add(LSTM(60, activation='tanh', return_sequences=True))
model1.add(LSTM(60, activation='tanh'))
model1.add(Dense(40, activation='relu'))
model1.add(Dense(2, activation='softmax'))
model1.summary()

model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])

history = model1.fit(X_train, y_train,
                    epochs=100,
                    batch_size=40,
                    verbose=1,callbacks=[es,mc,red_lr])

y_eva1 = y_test.idxmax(1)

y_pred1 = model1.predict(X_test)
prediction_index1= np.argmax(y_pred1,axis=1)

# get labels from one hot encoded y_train data
labels=pd.get_dummies(y_train).columns

# Iterate through all predicted indices using map method
predicted_labels1=list(map(lambda x: labels[x], prediction_index1))

model_eval_metrics(y_eva1,predicted_labels1,classification="TRUE")

"""### Model 2
1 embedding layer + 2 LSTM layers (with dropout regularization on the second layer)
"""

model2 = Sequential()
model2.add(Embedding(max_words, embedding_dim, input_length=maxlen))
model2.add(LSTM(60, activation='tanh', return_sequences=True))
model2.add(LSTM(60, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))
model2.add(Dense(40, activation='relu'))
model2.add(Dense(2, activation='softmax'))
model2.summary()

model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])

history = model2.fit(X_train, y_train,
                    epochs=100,
                    batch_size=40,
                    verbose=1,callbacks=[es,mc,red_lr])

y_eva2 = y_test.idxmax(1)

y_pred2 = model2.predict(X_test)
prediction_index2= np.argmax(y_pred2,axis=1)

# get labels from one hot encoded y_train data
labels=pd.get_dummies(y_train).columns

# Iterate through all predicted indices using map method
predicted_labels2=list(map(lambda x: labels[x], prediction_index2))

model_eval_metrics(y_eva2,predicted_labels2,classification="TRUE")

"""### Model 3
1 embedding layer + 1 conv 1D layer + 2 LSTM layers (with dropout regularization on the second LSTM layer)
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding

model3 = Sequential()
model3.add(Embedding(max_words, embedding_dim, input_length=maxlen))
model3.add(layers.Conv1D(60, 7, activation='relu')) 
model3.add(layers.MaxPooling1D(2))
model3.add(LSTM(40, activation='tanh', return_sequences=True))
model3.add(LSTM(60, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))
model3.add(Dense(40, activation='relu'))
model3.add(Dense(2, activation='softmax'))
model3.summary()

model3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])

history = model3.fit(X_train, y_train,
                    epochs=100,
                    batch_size=40,
                    verbose=1,callbacks=[es,mc,red_lr])

y_eva3 = y_test.idxmax(1)

y_pred3 = model3.predict(X_test)
prediction_index3= np.argmax(y_pred3,axis=1)

# get labels from one hot encoded y_train data
labels=pd.get_dummies(y_train).columns

# Iterate through all predicted indices using map method
predicted_labels3=list(map(lambda x: labels[x], prediction_index3))

model_eval_metrics(y_eva3,predicted_labels3,classification="TRUE")

"""### Model 4:
1 embedding layer + 1 bidirectional LSTM layer + 1 LSTM layer with dropout regularization
"""

from tensorflow.keras.layers import Bidirectional

model4 = Sequential()
model4.add(Embedding(max_words, embedding_dim, input_length=maxlen))
model4.add(Bidirectional(LSTM(40, activation='tanh', return_sequences=True)))
model4.add(LSTM(60, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))
model4.add(Dense(40, activation='relu'))
model4.add(Dense(2, activation='softmax'))
model4.summary()

model4.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])
history = model4.fit(X_train, y_train,
                    epochs=100,
                    batch_size=40,
                    verbose=1,callbacks=[es,mc,red_lr])

y_eva4 = y_test.idxmax(1)

y_pred4 = model4.predict(X_test)
prediction_index4= np.argmax(y_pred4,axis=1)

# get labels from one hot encoded y_train data
labels=pd.get_dummies(y_train).columns

# Iterate through all predicted indices using map method
predicted_labels4=list(map(lambda x: labels[x], prediction_index4))

model_eval_metrics(y_eva4,predicted_labels4,classification="TRUE")

"""### Summary

Model 1: 1 embedding layer + 2 LSTM layers (no dropout regularization)

Model 2: 1 embedding layer + 2 LSTM layers (with dropout regularization on the second LSTM layer)

Model 3: 1 embedding layer + 1 conv 1D layer + 2 LSTM layers (with dropout regularization on the second LSTM layer)

Model 4: 1 embedding layer + 1 bidirectional LSTM layer + 1 LSTM layer with dropout regularization
"""

model_eval_metrics(y_eva1,predicted_labels1,classification="TRUE")

model_eval_metrics(y_eva2,predicted_labels2,classification="TRUE")

model_eval_metrics(y_eva3,predicted_labels3,classification="TRUE")

model_eval_metrics(y_eva4,predicted_labels4,classification="TRUE")

"""My best model after experimenting with different layers is Model 4 with a 94.72% accuracy. It has the structure of one embedding layer, one bidirectional LSTM layer, and one LSTM layer with dropout regularization. This result makes sense because the bidirectional recurrent layer could gain information from past (backwards) and future (forward) states simultaneously. Also, this method does not require the input data to be fixed, and future input information is reachable from the current state. In the case of twitter text analysis, context of the text is a key element to understand the true meaning of the input. Therefore, bidirectional recurrent neural networks could be an effective approach.

Model 1 is the second best model to predict true and false tweets. This model doesn't have a dropout regularization to randomly drop out nodes during training. Dropout regularization is known to reduce overfitting and improve generalization error. This model might compromise on the geralization error to achieve a higher accuracy.

All models were excecuted with callback checkpoints, so the number of epochs is optimized without overfitting. All batch sizes were set to 40, but for future implementation, this factor could also be substitute with higher numbers.

It is worth noticing all models have similar accuracy with differences around 1%. Therefore, future experiment should be done to decide a truly distinguished algorithm.

### Submit the best model to the leader board for the Covid Misinformation AI Model Share competition
"""

# install aimodelshare library

! pip install aimodelshare --upgrade --extra-index-url https://test.pypi.org/simple/

import aimodelshare as ai
from aimodelshare.aimsonnx import model_to_onnx

# save preprocessor
ai.export_preprocessor(preprocessor,"")

# save model in onnx format
onnx_model = model_to_onnx(model4, framework='keras', transfer_learning=False, deep_learning=True)

with open("onnx_model.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

# set credentials for modeltoapi function 
# make sure you have uploaded your credentials.txt file
from aimodelshare.aws import set_credentials
api_url = "https://wvr23l2z9i.execute-api.us-east-1.amazonaws.com/prod/m"

set_credentials(apiurl=api_url,credential_file="credentials.txt", type="submit_model", manual=False)

ai.submit_model("onnx_model.onnx",
                api_url,
                prediction_submission=predicted_labels4,
                preprocessor="preprocessor.zip")

data=ai.get_leaderboard(api_url, verbose=3)
ai.leaderboard.stylize_leaderboard(data)

bestmodel = ai.aimsonnx.instantiate_model(api_url, version=67) 
bestmodel.summary()

bestmodel2 = ai.aimsonnx.instantiate_model(api_url, version=66) 
bestmodel2.summary()

bestmodel3 = ai.aimsonnx.instantiate_model(api_url, version=61) 
bestmodel3.summary()

ai.aimsonnx.compare_models(api_url, version_list=[67,61])

"""The top two models didn't make use of LSTM models, but the third best model used a bidirectional layer with a LSTM layer. Because of the bidirectional layer, there are more parameters in each layer. This model is similar to my best model and could be possibly improved by tuning the batch size and dimentionality.

### Feed the model some realistic tweets to see if it returns meaningful/useful results
"""

# real test tweets
test1 = "Half of all adults in the US have received at least one Covid-19 shot, the government says."
test2 = "#DYK? Older adults are at high risk of getting seriously ill with #COVID19. To help protect them, older adults, their caregivers, and families all need to get vaccinated. Learn how community organizations can help: "
# fake test tweets
test3 = "Coronavirus is just a variant of flu. There's nothing to be alarmed about"
test4 = "China should be responsible for covid."

testlist = [test1, test2, test3, test4]
testdf = pd.DataFrame(testlist)
testdf['label'] = ['real','real','fake','fake']
testdf.iloc[:,0]

y_pred5 = model4.predict(preprocessor(testdf.iloc[:, 0], maxlen=40, max_words=10000))

prediction= np.argmax(y_pred5 ,axis=1)
labels=pd.get_dummies(y_train).columns
predicted_labels5=list(map(lambda x: labels[x], prediction_index))
testdf['predicted'] = pd.Series(predicted_labels5)

testdf

"""Well... the best model failed to predict a real information tweet from the CDC. Test4 also failed, but may be the result of political reasons. More analysis could be done to identify how the length and tone of the tweet could influence on the result."""

pip install nbconvert

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --to html /content/Covid_misinformation.ipynb